{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T09:05:20.595907Z",
     "start_time": "2021-04-15T09:05:05.739303Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mikhailzaytsev/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/mikhailzaytsev/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/mikhailzaytsev/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mikhailzaytsev/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import string\n",
    "import re\n",
    "import gensim\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import Counter\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "STOP_WORDS = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"An increasing number of high-performance netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision and accuracy of portable meter Accut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We consider the following nonlinear Schrödinge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"High-throughput assays for enzyme catalysis t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Three alternative routes, using the heterobif...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  \"An increasing number of high-performance netw...\n",
       "1  Precision and accuracy of portable meter Accut...\n",
       "2  We consider the following nonlinear Schrödinge...\n",
       "3  \"High-throughput assays for enzyme catalysis t...\n",
       "4  \"Three alternative routes, using the heterobif..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('abstracts.csv', header=None) # загрузим данные\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"An increasing number of high-performance networks provision dedicated channels through circuit switching or MPLS/GMPLS techniques to support large data transfer. The link bandwidths in such networks are typically shared by multiple users through advance reservation, resulting in varying bandwidth availability in future time. Developing efficient scheduling algorithms for advance bandwidth reservation has become a critical task to improve the utilization of network resources and meet the transport requirements of application users. We consider an exhaustive combination of different path and bandwidth constraints and formulate four types of advance bandwidth scheduling problems, with the same objective to minimize the data transfer end time for a given transfer request with a prespecified data size: 1) fixed path with fixed bandwidth (FPFB); 2) fixed path with variable bandwidth (FPVB); 3) variable path with fixed bandwidth (VPFB); and 4) variable path with variable bandwidth (VPVB). For VPFB and VPVB, we further consider two subcases where the path switching delay is negligible or nonnegligible. We propose an optimal algorithm for each of these scheduling problems except for FPVB and VPVB with nonnegligible path switching delay, which are proven to be NP-complete and nonapproximable, and then tackled by heuristics. The performance superiority of these heuristics is verified by extensive experimental results in a large set of simulated networks in comparison to optimal and greedy strategies. ']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.iloc[0]) # пример элемента датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_idx = np.where(df.iloc[:,0].apply(len)<100)[0] # выделим тексты короче 100 символов\n",
    "df.drop(index=short_idx, inplace=True) # удалим такие тексты\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функции для предобработки текста\n",
    "\n",
    "def remove_nonASCII(text):\n",
    "    \"\"\"Удаляем non-ASCII символы\"\"\"\n",
    "    cleaned_text = ''.join([x for x in text if x in string.printable])\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_URL(text):\n",
    "    \"\"\"Удаляем ссылки\"\"\"\n",
    "    url = re.compile(r'http\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',text)\n",
    "\n",
    "def remove_punct(text):\n",
    "    \"\"\"Удаляем знаки препинания\"\"\"\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "def remove_individ_letters(text):\n",
    "    \"\"\"Удаляем одиночные буквы\"\"\"\n",
    "    return re.sub(r'\\b\\w.?\\b','', text) \n",
    "\n",
    "def remove_numbers(text):\n",
    "    \"\"\"Удаляем цифры\"\"\"\n",
    "    return re.sub(r'\\d*','', text) \n",
    "\n",
    "def remove_stop_words(text):\n",
    "    \"\"\"Удаление стоп слов\"\"\"\n",
    "    new_sent = ' '.join([i for i in text.split() if i not in STOP_WORDS])\n",
    "    return new_sent\n",
    "\n",
    "def process_text(text):\n",
    "    text = remove_nonASCII(text)\n",
    "    text = remove_URL(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = remove_punct(text)\n",
    "    text = remove_individ_letters(text)\n",
    "    return text\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Переведем тэги с nltk.pos_tag в тэги, которые принимает lemmatize() метод. \n",
    "    Если такого тэга нет, то по умолчанию возвращается существительное.\"\"\" \n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper() # выделяем тэг слова\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN) # переводим все слова к соответствующей форме, либо к существительному\n",
    "\n",
    "def clean_text(text, lemmatize=True, remove_stopwords=True):\n",
    "    \"\"\"Очищаем текст\"\"\"\n",
    "    if remove_stopwords:\n",
    "        text = remove_stop_words(text.lower()) # удаляем стоп-слова и приводим все к нижнему регистру\n",
    "    text = process_text(text) # очищаем текст\n",
    "    if lemmatize:\n",
    "        lemmatizer = WordNetLemmatizer() # лемматизируем\n",
    "        return ' '.join([lemmatizer.lemmatize(word, pos=get_wordnet_pos(word)) for word in word_tokenize(text)])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.iloc[:, 0].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"An increasing number of high-performance networks provision dedicated channels through circuit switching or MPLS/GMPLS techniques to support large data transfer. The link bandwidths in such networks are typically shared by multiple users through advance reservation, resulting in varying bandwidth availability in future time. Developing efficient scheduling algorithms for advance bandwidth reservation has become a critical task to improve the utilization of network resources and meet the transport requirements of application users. We consider an exhaustive combination of different path and bandwidth constraints and formulate four types of advance bandwidth scheduling problems, with the same objective to minimize the data transfer end time for a given transfer request with a prespecified data size: 1) fixed path with fixed bandwidth (FPFB); 2) fixed path with variable bandwidth (FPVB); 3) variable path with fixed bandwidth (VPFB); and 4) variable path with variable bandwidth (VPVB). For VPFB and VPVB, we further consider two subcases where the path switching delay is negligible or nonnegligible. We propose an optimal algorithm for each of these scheduling problems except for FPVB and VPVB with nonnegligible path switching delay, which are proven to be NP-complete and nonapproximable, and then tackled by heuristics. The performance superiority of these heuristics is verified by extensive experimental results in a large set of simulated networks in comparison to optimal and greedy strategies. ']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'increase number highperformance network provision dedicate channel circuit switch mplsgmpls technique support large data transfer link bandwidth network typically share multiple user advance reservation result vary bandwidth availability future time develop efficient schedule algorithm advance bandwidth reservation become critical task improve utilization network resource meet transport requirement application user consider exhaustive combination different path bandwidth constraint formulate four type advance bandwidth schedule problem objective minimize data transfer end time give transfer request prespecified data size fix path fix bandwidth fpfb fix path variable bandwidth fpvb variable path fix bandwidth vpfb variable path variable bandwidth vpvb vpfb vpvb consider two subcases path switch delay negligible nonnegligible propose optimal algorithm schedule problem except fpvb vpvb nonnegligible path switch delay proven npcomplete nonapproximable tackle heuristic performance superiority heuristic verify extensive experimental result large set simulated network comparison optimal greedy strategy'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
