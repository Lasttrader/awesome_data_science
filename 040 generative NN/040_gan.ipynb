{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27636408",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Импорт и установка зависимостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b06e37e6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#!pip install imageio\n",
    "#!pip install git+https://github.com/tensorflow/docs\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d50491",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Загрузка данных и подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "981b6fa3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data() # загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab035393",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 255) / 255  # Нормализуем изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7aab57d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_dataset = tf.data.Dataset\\\n",
    ".from_tensor_slices(train_images)\\\n",
    ".shuffle(BUFFER_SIZE)\\\n",
    ".batch(BATCH_SIZE) # формируем батчи данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6488b916",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Построение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27f03648",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# формируем архитектуру модели генератора, который будет пытаться воссоздать изображение\n",
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,))) # подается шум на вход\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Reshape((7, 7, 256))) # изменяем размерность\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(filters=128, \n",
    "                                     kernel_size=(5, 5), \n",
    "                                     strides=(1, 1), \n",
    "                                     padding='same', \n",
    "                                     use_bias=False)) # делаем upsampling\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(filters=64, \n",
    "                                     kernel_size=(5, 5), \n",
    "                                     strides=(2, 2), \n",
    "                                     padding='same', \n",
    "                                     use_bias=False)) # делаем upsampling\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(filters=1, \n",
    "                                     kernel_size=(5, 5), \n",
    "                                     strides=(2, 2), \n",
    "                                     padding='same', \n",
    "                                     use_bias=False, \n",
    "                                     activation='tanh')) # делаем upsampling\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a13fc848",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17bd97c70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = make_generator_model() # инициализируем генератор\n",
    "noise = tf.random.normal([1, 100]) #  шум\n",
    "generated_image = generator(noise)  # картинка, генерируемая необученным генератором\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ac936e3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Определяем архитектуру дискриминатора, который будет распознавать оригинальное изображение или нет\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(filters=64, \n",
    "                            kernel_size=(5, 5), \n",
    "                            strides=(2, 2), \n",
    "                            padding='same',\n",
    "                            input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d0dea57",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.00224282]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model() # определяем дискриминатор\n",
    "decision = discriminator(generated_image) # предсказание еще не тренированным дискриминатором\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c05311d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "# определим функции потерь генератора и дискриминатора\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = loss(tf.ones_like(real_output), real_output) # потери для реальных изображений\n",
    "    fake_loss = loss(tf.zeros_like(fake_output), fake_output)# потери для фейковых изображений\n",
    "    total_loss = real_loss + fake_loss # суммарные потери\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return loss(tf.ones_like(fake_output), fake_output) # насколько сгенирируемое похоже на реальное\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5af98e75",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\") # путь для сохранения промежуточных результатов\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator) # сохранение промежуточных моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8d5c879",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Тренировка модели\n",
    "\n",
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim]) # генерация шума на вход генератору"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef5e56e4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images): # определим шаг обучения\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, \n",
    "                                               generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, \n",
    "                                                    discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, \n",
    "                                            generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, \n",
    "                                                discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30f9c5c6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        for image_batch in dataset:\n",
    "            train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as you go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "    # Generate after the final epoch\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator, epochs, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9883019e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "\n",
    "    predictions = model(test_input, training=False) # не тренируем слои\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 255 + 255, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b82558",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d70f101c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def display_image(epoch_no):\n",
    "    return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa3d09d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "anim_file = 'dcgan.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "    filenames = glob.glob('image*.png')\n",
    "    filenames = sorted(filenames)\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f6356d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensorflow_docs.vis.embed as embed\n",
    "embed.embed_file(anim_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
